"""
åŒè‰²çƒé¢„æµ‹åˆ†æ - èƒ†æ‹–æŠ•æ³¨é¢„æµ‹ä¼˜åŒ–ç‰ˆï¼ˆè’™ç‰¹å¡æ´›é‡‡æ · + ç²¾è‹±é€‰æ‹©ï¼‰
"""
import pymysql
import pandas as pd
import numpy as np
from scipy import stats
from collections import Counter
import matplotlib.pyplot as plt
from datetime import datetime
import os
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# ============== é…ç½®åŒºåŸŸ ==============
DB_CONFIG = {
    'host': 'localhost',
    'port': 3306,
    'user': 'root',
    'password': 'reven@0504',
    'database': 'lottery_db',
    'charset': 'utf8mb4'
}

OUTPUT_DIR = r"D:\Mydevelopment\MultiContentProject\Mylottery\dan_tuo_prediction"

# ============== èƒ†æ‹–å‚æ•° ==============
N_DAN_RED = 4      # çº¢çƒèƒ†ç æ•°é‡
N_TUO_HOT_RED = 3  # çº¢çƒæ‹–ç æ•°é‡ï¼ˆé«˜æ‹ŸåˆåŒºï¼‰
N_TUO_COLD_RED = 2 # çº¢çƒæ‹–ç æ•°é‡ï¼ˆå†·é—¨åŒºï¼‰

N_DAN_BLUE = 1     # è“çƒèƒ†ç æ•°é‡
N_TUO_BLUE = 2     # è“çƒæ‹–ç æ•°é‡

# ============== ä¼˜åŒ–å‚æ•° ==============
N_SAMPLES = 500        # è’™ç‰¹å¡æ´›é‡‡æ ·æ¬¡æ•°
N_TOP_SELECT = 10      # æœ€ç»ˆé€‰å‡ºTOPå¤šå°‘ç»„
N_DISPLAY = 5          # æ§åˆ¶å°æ˜¾ç¤ºå‰å¤šå°‘ç»„


def load_data():
    """ä»æ•°æ®åº“åŠ è½½æ•°æ®"""
    print("ğŸ“¥ æ­£åœ¨ä»æ•°æ®åº“åŠ è½½æ•°æ®...")

    conn = pymysql.connect(**DB_CONFIG)
    df = pd.read_sql("""
        SELECT period, red1, red2, red3, red4, red5, red6, blue, draw_date
        FROM lottery_data 
        ORDER BY CAST(period AS UNSIGNED)
    """, conn)
    conn.close()

    print(f"   âœ… åŠ è½½å®Œæˆ: {len(df)} æ¡è®°å½•")
    print(f"   ğŸ“… {df['draw_date'].min()} ~ {df['draw_date'].max()}")

    return df


def fit_kde(data, x):
    """æ ¸å¯†åº¦ä¼°è®¡"""
    kde = stats.gaussian_kde(data)
    pdf = kde(x)
    return pdf / pdf.sum()


def fit_beta(data, x):
    """Betaåˆ†å¸ƒæ‹Ÿåˆ"""
    normalized = (data - 1) / 32

    try:
        a, b, loc, scale = stats.beta.fit(normalized, floc=0, fscale=1)
        x_norm = (x - 1) / 32
        pdf = stats.beta.pdf(x_norm, a, b)
        return pdf / pdf.sum()
    except:
        return np.ones_like(x) / len(x)


def fit_trimodal(data, x):
    """æ‰‹åŠ¨å®ç°ä¸‰å³°é«˜æ–¯æ··åˆæ¨¡å‹"""
    n_samples = len(data)
    x = np.array(x)

    quantiles = np.percentile(data, [100 / (3 + 1) * i for i in range(1, 4)])
    means = sorted(quantiles.copy())
    stds = [np.std(data) / np.sqrt(3)] * 3
    weights = np.ones(3) / 3

    for _ in range(50):
        responsibilities = np.zeros((n_samples, 3))
        for k in range(3):
            responsibilities[:, k] = weights[k] * stats.norm.pdf(data, means[k], stds[k] + 0.1)
        responsibilities = responsibilities / (responsibilities.sum(axis=1, keepdims=True) + 1e-10)

        for k in range(3):
            nk = responsibilities[:, k].sum()
            weights[k] = nk / n_samples
            means[k] = (responsibilities[:, k] * data).sum() / (nk + 1e-10)
            var = (responsibilities[:, k] * (data - means[k]) ** 2).sum() / (nk + 1e-10)
            stds[k] = np.sqrt(var + 0.1)

    pdf = np.zeros_like(x)
    for k in range(3):
        pdf += weights[k] * stats.norm.pdf(x, means[k], stds[k] + 0.1)

    return pdf / (pdf.sum() + 1e-10)


def fit_distributions(df):
    """æ‹Ÿåˆåˆ†å¸ƒï¼Œè¿”å›ç»¼åˆæ¦‚ç‡"""
    print("\nğŸ“Š æ­£åœ¨æ‹Ÿåˆåˆ†å¸ƒ...")

    red_cols = ['red1', 'red2', 'red3', 'red4', 'red5', 'red6']
    all_reds = np.array([df[col].values for col in red_cols]).flatten()

    x = np.linspace(1, 33, 1000)

    print("   1/4 æ ¸å¯†åº¦ä¼°è®¡...")
    pdf_kde = fit_kde(all_reds, x)

    print("   2/4 Betaåˆ†å¸ƒ...")
    pdf_beta = fit_beta(all_reds, x)

    print("   3/4 ä¸‰å³°é«˜æ–¯æ··åˆ...")
    pdf_gmm = fit_trimodal(all_reds, x)

    print("   4/4 é¢‘ç‡åˆ†æ...")
    freq_counts = Counter(all_reds)
    pdf_freq = np.zeros_like(x)
    for num in range(1, 34):
        idx = np.abs(x - num).argmin()
        pdf_freq[idx] = freq_counts.get(num, 0)
    pdf_freq = pdf_freq / (pdf_freq.sum() + 1e-10)

    print("   ç»¼åˆæƒé‡è®¡ç®—...")
    combined = (
            0.30 * pdf_kde +
            0.25 * pdf_beta +
            0.25 * pdf_gmm +
            0.20 * pdf_freq
    )
    combined = combined / combined.sum()

    red_probs = {}
    for num in range(1, 34):
        idx = np.abs(x - num).argmin()
        red_probs[num] = combined[idx]

    total = sum(red_probs.values())
    for num in red_probs:
        red_probs[num] /= total

    return red_probs, x, combined


def calculate_blue_probs(df):
    """è®¡ç®—è“çƒæ¦‚ç‡ï¼ˆå¸¦æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘ï¼‰"""
    blue_counts = Counter(df['blue'].tolist())
    total = len(df)

    blue_probs = {}
    for num in range(1, 17):
        count = blue_counts.get(num, 0)
        blue_probs[num] = (count + 1) / (total + 16)

    return blue_probs


def weighted_random_choice(probs_dict, n, exclude=None):
    """æ ¹æ®æƒé‡éšæœºæŠ½å–nä¸ªæ•°å­—"""
    if exclude is None:
        exclude = set()

    items = [(k, v) for k, v in probs_dict.items() if k not in exclude]
    nums = [k for k, v in items]
    weights = np.array([v for k, v in items])

    if weights.sum() == 0:
        weights = np.ones(len(nums))

    weights = weights / weights.sum()

    selected = np.random.choice(nums, size=min(n, len(nums)), replace=False, p=weights)

    return list(selected)


def select_cold_numbers(probs_dict, n, exclude=None):
    """é€‰å–æœ€å†·é—¨çš„nä¸ªæ•°å­—"""
    if exclude is None:
        exclude = set()

    sorted_items = sorted(probs_dict.items(), key=lambda x: x[1])

    selected = []
    for num, prob in sorted_items:
        if num not in exclude:
            selected.append((num, prob))
            if len(selected) >= n:
                break

    return selected


def select_hot_numbers(probs_dict, n, exclude=None):
    """é€‰å–æœ€çƒ­é—¨çš„nä¸ªæ•°å­—"""
    if exclude is None:
        exclude = set()

    sorted_items = sorted(probs_dict.items(), key=lambda x: x[1], reverse=True)

    selected = []
    for num, prob in sorted_items:
        if num not in exclude:
            selected.append((num, prob))
            if len(selected) >= n:
                break

    return selected


def build_red_dantuo_pool(red_probs, n_dan=4, n_tuo_hot=3, n_tuo_cold=2, seed=None):
    """æ„å»ºçº¢çƒèƒ†æ‹–å·ç æ± """
    if seed is not None:
        np.random.seed(seed)

    hot_candidates = select_hot_numbers(red_probs, 12)
    hot_nums = [n for n, p in hot_candidates]
    hot_probs = {n: red_probs[n] for n in hot_nums}

    dan = weighted_random_choice(hot_probs, n_dan)
    dan_set = set(dan)

    tuo_hot = weighted_random_choice(hot_probs, n_tuo_hot, exclude=dan_set)

    cold_candidates = select_cold_numbers(red_probs, 12, exclude=dan_set)
    cold_nums = [n for n, p in cold_candidates]
    tuo_cold = weighted_random_choice({n: red_probs[n] for n in cold_nums}, n_tuo_cold)

    tuo = tuo_hot + tuo_cold
    tuo_set = set(tuo)

    dan = [d for d in dan if d not in tuo_set]
    tuo = [t for t in tuo if t not in dan_set]

    full_pool = sorted(dan + tuo)

    return dan, tuo, full_pool


def build_blue_dantuo_pool(blue_probs, n_dan=1, n_tuo=2, seed=None):
    """æ„å»ºè“çƒèƒ†æ‹–å·ç æ± """
    if seed is not None:
        np.random.seed(seed)

    dan = weighted_random_choice(blue_probs, n_dan)
    dan_set = set(dan)

    tuo = weighted_random_choice(blue_probs, n_tuo, exclude=dan_set)

    full_pool = dan + tuo

    return dan, tuo, full_pool


def calculate_pool_statistics(dan, tuo, probs, total_nums):
    """è®¡ç®—å·ç æ± çš„ç»Ÿè®¡ç‰¹æ€§"""
    expected_hits = sum(probs[n] for n in dan + tuo)
    dan_prob = sum(probs[n] for n in dan)
    tuo_prob = sum(probs[n] for n in tuo)
    theoretical = (len(dan) + len(tuo)) / total_nums
    coverage = expected_hits / theoretical if theoretical > 0 else 0

    return {
        'expected_hits': expected_hits,
        'dan_prob': dan_prob,
        'tuo_prob': tuo_prob,
        'coverage': coverage,
        'total_count': len(dan) + len(tuo)
    }


def monte_carlo_sampling(red_probs, blue_probs, n_samples=500):
    """è’™ç‰¹å¡æ´›é‡‡æ · - ç”Ÿæˆå¤§é‡å€™é€‰é¢„æµ‹ç»„"""
    all_predictions = []

    for i in range(n_samples):
        dan_red, tuo_red, full_pool_red = build_red_dantuo_pool(
            red_probs,
            n_dan=N_DAN_RED,
            n_tuo_hot=N_TUO_HOT_RED,
            n_tuo_cold=N_TUO_COLD_RED,
            seed=None  # å®Œå…¨éšæœº
        )

        dan_blue, tuo_blue, full_pool_blue = build_blue_dantuo_pool(
            blue_probs,
            n_dan=N_DAN_BLUE,
            n_tuo=N_TUO_BLUE,
            seed=None
        )

        red_stats = calculate_pool_statistics(dan_red, tuo_red, red_probs, 33)
        blue_stats = calculate_pool_statistics(dan_blue, tuo_blue, blue_probs, 16)

        prediction = {
            'sample_id': i,
            'dan_red': sorted(dan_red),
            'tuo_red': sorted(tuo_red),
            'red_pool': sorted(dan_red + tuo_red),
            'dan_blue': sorted(dan_blue),
            'tuo_blue': sorted(tuo_blue),
            'blue_pool': sorted(dan_blue + tuo_blue),
            'red_stats': red_stats,
            'blue_stats': blue_stats,
            'total_expected': red_stats['expected_hits'] + blue_stats['expected_hits']
        }
        all_predictions.append(prediction)

    return all_predictions


def elite_selection(all_predictions, top_k=10):
    """ç²¾è‹±é€‰æ‹© - ä»æ‰€æœ‰é‡‡æ ·ä¸­æŒ‘é€‰æœ€ä¼˜çš„top_kç»„"""
    sorted_predictions = sorted(
        all_predictions,
        key=lambda x: x['total_expected'],
        reverse=True
    )
    return sorted_predictions[:top_k]


def generate_optimized_predictions(df, n_samples=500, top_k=10):
    """ç”Ÿæˆä¼˜åŒ–åçš„é¢„æµ‹ç»“æœ"""
    print("\n" + "=" * 70)
    print("ğŸ¯ èƒ†æ‹–æŠ•æ³¨é¢„æµ‹ - ä¼˜åŒ–ç‰ˆï¼ˆè’™ç‰¹å¡æ´›é‡‡æ · + ç²¾è‹±é€‰æ‹©ï¼‰")
    print("=" * 70)

    red_probs, x, pdf = fit_distributions(df)
    blue_probs = calculate_blue_probs(df)

    print("\nğŸ“ˆ çº¢çƒæ‹Ÿåˆæ¦‚ç‡TOP15:")
    top15 = select_hot_numbers(red_probs, 15)
    for i, (num, prob) in enumerate(top15, 1):
        deviation = (prob - 1 / 33) / (1 / 33) * 100
        sign = '+' if deviation > 0 else ''
        print(f"   {i:2d}. {num:02d}: {prob:.5f} ({sign}{deviation:.1f}%)")

    print("\nğŸ“ˆ è“çƒæ‹Ÿåˆæ¦‚ç‡TOP8:")
    top8 = select_hot_numbers(blue_probs, 8)
    for i, (num, prob) in enumerate(top8, 1):
        deviation = (prob - 1 / 16) / (1 / 16) * 100
        sign = '+' if deviation > 0 else ''
        print(f"   {i:2d}. {num:02d}: {prob:.5f} ({sign}{deviation:.1f}%)")

    print("\nğŸ“‰ çº¢çƒå†·é—¨TOP5:")
    cold5 = select_cold_numbers(red_probs, 5)
    for i, (num, prob) in enumerate(cold5, 1):
        deviation = (prob - 1 / 33) / (1 / 33) * 100
        sign = '+' if deviation > 0 else ''
        print(f"   {i:2d}. {num:02d}: {prob:.5f} ({sign}{deviation:.1f}%)")

    # è’™ç‰¹å¡æ´›é‡‡æ ·
    print(f"\nğŸ² å¼€å§‹è’™ç‰¹å¡æ´›é‡‡æ · ({n_samples}æ¬¡)...")
    all_samples = monte_carlo_sampling(red_probs, blue_probs, n_samples=n_samples)

    # ç»Ÿè®¡é‡‡æ ·ç»“æœ
    all_expected = [p['total_expected'] for p in all_samples]
    print(f"   ğŸ“Š é‡‡æ ·ç»Ÿè®¡:")
    print(f"      æœŸæœ›å‘½ä¸­ - æœ€é«˜: {max(all_expected):.3f}, "
          f"å¹³å‡: {np.mean(all_expected):.3f}, "
          f"æœ€ä½: {min(all_expected):.3f}")

    # ç²¾è‹±é€‰æ‹©
    print(f"\nğŸ† æ‰§è¡Œç²¾è‹±é€‰æ‹© (TOP {top_k})...")
    top_predictions = elite_selection(all_samples, top_k)

    best = top_predictions[0]
    worst = top_predictions[-1]
    print(f"   æœ€ä½³æœŸæœ›: {best['total_expected']:.3f}")
    print(f"   æœ€å·®æœŸæœ›: {worst['total_expected']:.3f}")
    print(f"   ä¼˜åŒ–å¹…åº¦: +{(best['total_expected'] - np.mean(all_expected)):.3f} "
          f"(ç›¸æ¯”å¹³å‡)")

    # æ˜¾ç¤ºTOPç»„
    display_count = min(N_DISPLAY, len(top_predictions))
    print(f"\nğŸ“‹ TOP {display_count} é¢„æµ‹å·ç :")
    print("-" * 70)

    for i, pred in enumerate(top_predictions[:display_count], 1):
        print(f"\nã€é¢„æµ‹{i}ã€‘ (æ ·æœ¬#{pred['sample_id']})")
        print(f"  ğŸŸ¥ çº¢çƒèƒ†ç  ({len(pred['dan_red'])}ä¸ª): ", end="")
        print(", ".join([f"{n:02d}" for n in pred['dan_red']]))
        print(f"  ğŸŸ¨ çº¢çƒæ‹–ç  ({len(pred['tuo_red'])}ä¸ª): ", end="")
        print(", ".join([f"{n:02d}" for n in pred['tuo_red']]))
        print(f"     â””â”€ çƒ­åŒº: {[f'{n:02d}' for n in sorted(pred['tuo_red'][:N_TUO_HOT_RED])]}", end=" ")
        print(f"+ å†·åŒº: {[f'{n:02d}' for n in sorted(pred['tuo_red'][N_TUO_HOT_RED:])]}")
        print(f"  ğŸ”µ è“çƒèƒ†ç  ({len(pred['dan_blue'])}ä¸ª): ", end="")
        print(", ".join([f"{n:02d}" for n in pred['dan_blue']]))
        print(f"  ğŸŸ¦ è“çƒæ‹–ç  ({len(pred['tuo_blue'])}ä¸ª): ", end="")
        print(", ".join([f"{n:02d}" for n in pred['tuo_blue']]))
        print(f"  ğŸ“Š è¦†ç›–çº¢çƒ: {len(pred['red_pool'])}ä¸ª | è“çƒ: {len(pred['blue_pool'])}ä¸ª")
        print(f"  ğŸ“ˆ æœŸæœ›å‘½ä¸­: çº¢{pred['red_stats']['expected_hits']:.2f} + "
              f"è“{pred['blue_stats']['expected_hits']:.2f} = "
              f"æ€»è®¡{pred['total_expected']:.2f}")

    return top_predictions, all_samples, red_probs, blue_probs, x, pdf


def plot_optimized_charts(predictions, all_samples, red_probs, blue_probs, x_vals, pdf, output_dir):
    """ç»˜åˆ¶ä¼˜åŒ–åçš„å¯è§†åŒ–å›¾è¡¨"""
    os.makedirs(output_dir, exist_ok=True)

    # å›¾è¡¨1ï¼šç»¼åˆåˆ†æ
    fig1, axes1 = plt.subplots(2, 2, figsize=(14, 10))

    # å­å›¾1ï¼šçº¢çƒæ¦‚ç‡åˆ†å¸ƒ
    ax1 = axes1[0, 0]
    nums = list(range(1, 34))
    probs = [red_probs[n] for n in nums]

    colors = []
    for n in nums:
        if n in predictions[0]['dan_red']:
            colors.append('#FF4444')
        elif n in predictions[0]['tuo_red']:
            colors.append('#FFA500')
        else:
            colors.append('#CCCCCC')

    ax1.bar(nums, probs, color=colors, edgecolor='white', linewidth=0.5)
    ax1.axhline(y=1 / 33, color='blue', linestyle='--', alpha=0.5, label='å‡åŒ€åˆ†å¸ƒ')
    ax1.set_xlabel('Red Ball Number', fontsize=11)
    ax1.set_ylabel('Fitted Probability', fontsize=11)
    ax1.set_title('Red Ball Fitted Probability Distribution (Best Prediction)', fontsize=12, fontweight='bold')
    ax1.set_xticks(range(1, 34, 2))

    from matplotlib.patches import Patch
    legend_elements = [
        Patch(facecolor='#FF4444', label='Dan (Key)'),
        Patch(facecolor='#FFA500', label='Tuo (Extended)'),
        Patch(facecolor='#CCCCCC', label='Not Selected')
    ]
    ax1.legend(handles=legend_elements, loc='upper right')

    # å­å›¾2ï¼šTOPé¢„æµ‹çš„èƒ†æ‹–åˆ†å¸ƒ
    ax2 = axes1[0, 1]

    dan_counts = np.zeros(34)
    tuo_counts = np.zeros(34)

    for pred in predictions:
        for n in pred['dan_red']:
            dan_counts[n - 1] += 1
        for n in pred['tuo_red']:
            tuo_counts[n - 1] += 1

    x_pos = np.arange(34)
    width = 0.6

    ax2.bar(x_pos, dan_counts, width, label='Dan Count', color='#FF4444')
    ax2.bar(x_pos, tuo_counts, width, bottom=dan_counts, label='Tuo Count', color='#FFA500')
    ax2.set_xlabel('Red Ball Number', fontsize=11)
    ax2.set_ylabel('Count', fontsize=11)
    ax2.set_title(f'Dan/Tuo Distribution in TOP {len(predictions)}', fontsize=12, fontweight='bold')
    ax2.set_xticks(x_pos)
    ax2.set_xticklabels([str(i) for i in range(1, 35)])
    ax2.legend()

    # å­å›¾3ï¼šè’™ç‰¹å¡æ´›é‡‡æ ·åˆ†å¸ƒ
    ax3 = axes1[1, 0]

    all_expected = [p['total_expected'] for p in all_samples]

    ax3.hist(all_expected, bins=30, alpha=0.7, color='steelblue',
             label=f'All Samples (n={len(all_samples)})', edgecolor='white')
    ax3.axvline(x=np.mean(all_expected), color='blue', linestyle='--',
                linewidth=2, label=f'Mean: {np.mean(all_expected):.3f}')
    ax3.axvline(x=max(all_expected), color='green', linestyle='--',
                linewidth=2, label=f'Max: {max(all_expected):.3f}')

    for pred in predictions:
        ax3.axvline(x=pred['total_expected'], color='red', alpha=0.3, linewidth=1)

    ax3.set_xlabel('Total Expected Hits', fontsize=11)
    ax3.set_ylabel('Frequency', fontsize=11)
    ax3.set_title('Monte Carlo Sampling Distribution', fontsize=12, fontweight='bold')
    ax3.legend(loc='upper left')

    # å­å›¾4ï¼šæœŸæœ›å‘½ä¸­æ•°å¯¹æ¯”
    ax4 = axes1[1, 1]

    groups = [f'TOP {p["sample_id"] % 10 + 1}' for p in predictions]
    red_expected = [p['red_stats']['expected_hits'] for p in predictions]
    blue_expected = [p['blue_stats']['expected_hits'] for p in predictions]

    x = np.arange(len(groups))
    width = 0.35

    bars1 = ax4.bar(x - width / 2, red_expected, width, label='Red Expected Hits', color='#FF6B6B')
    bars2 = ax4.bar(x + width / 2, blue_expected, width, label='Blue Expected Hits', color='#4ECDC4')

    ax4.set_ylabel('Expected Hits', fontsize=11)
    ax4.set_title('Expected Hits by Prediction (TOP Selected)', fontsize=12, fontweight='bold')
    ax4.set_xticks(x)
    ax4.set_xticklabels(groups, fontsize=9)
    ax4.legend()
    ax4.axhline(y=1, color='gray', linestyle='--', alpha=0.5)

    for bar in bars1:
        height = bar.get_height()
        ax4.annotate(f'{height:.2f}',
                     xy=(bar.get_x() + bar.get_width() / 2, height),
                     xytext=(0, 3), textcoords="offset points",
                     ha='center', va='bottom', fontsize=8)
    for bar in bars2:
        height = bar.get_height()
        ax4.annotate(f'{height:.2f}',
                     xy=(bar.get_x() + bar.get_width() / 2, height),
                     xytext=(0, 3), textcoords="offset points",
                     ha='center', va='bottom', fontsize=8)

    plt.tight_layout()
    plt.savefig(f'{output_dir}/optimized_analysis.png', dpi=150, bbox_inches='tight')
    plt.close()
    print(f"   âœ… optimized_analysis.png")

    # å›¾è¡¨2ï¼šä¼˜åŒ–æ•ˆæœå¯¹æ¯”
    fig5, ax = plt.subplots(figsize=(10, 6))

    all_expected = [p['total_expected'] for p in all_samples]

    n, bins, patches = ax.hist(all_expected, bins=40, alpha=0.7,
                                color='steelblue', edgecolor='white')

    top_threshold = predictions[-1]['total_expected']
    for i, patch in enumerate(patches):
        if bins[i] >= top_threshold:
            patch.set_facecolor('#FF6B6B')
            patch.set_alpha(0.8)

    ax.axvline(x=np.mean(all_expected), color='blue', linestyle='--',
               linewidth=2, label=f'Overall Mean: {np.mean(all_expected):.3f}')
    ax.axvline(x=top_threshold, color='red', linestyle='-',
               linewidth=2, label=f'TOP Selection Threshold: {top_threshold:.3f}')

    ax.axvspan(top_threshold, max(all_expected) + 0.1, alpha=0.1, color='red')

    ax.set_xlabel('Total Expected Hits', fontsize=12)
    ax.set_ylabel('Frequency', fontsize=12)
    ax.set_title(f'Monte Carlo Optimization Effect (n={len(all_samples)}, TOP {len(predictions)})',
                 fontsize=14, fontweight='bold')
    ax.legend(loc='upper left')

    stats_text = (
        f"Overall Statistics:\n"
        f"Mean: {np.mean(all_expected):.3f}\n"
        f"Std: {np.std(all_expected):.3f}\n"
        f"Min: {min(all_expected):.3f}\n"
        f"Max: {max(all_expected):.3f}\n"
        f"\nTOP {len(predictions)} Selected:\n"
        f"Best: {predictions[0]['total_expected']:.3f}\n"
        f"Threshold: {top_threshold:.3f}\n"
        f"Improvement: +{(predictions[0]['total_expected'] - np.mean(all_expected)):.3f}"
    )
    ax.text(0.98, 0.98, stats_text, transform=ax.transAxes,
            fontsize=10, verticalalignment='top', horizontalalignment='right',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    plt.tight_layout()
    plt.savefig(f'{output_dir}/optimization_effect.png', dpi=150, bbox_inches='tight')
    plt.close()
    print(f"   âœ… optimization_effect.png")


def save_optimized_results(predictions, all_samples, red_probs, blue_probs, output_dir):
    """ä¿å­˜ä¼˜åŒ–åçš„é¢„æµ‹ç»“æœ"""
    os.makedirs(output_dir, exist_ok=True)

    with open(f'{output_dir}/optimized_predictions.txt', 'w', encoding='utf-8') as f:
        f.write("=" * 70 + "\n")
        f.write("         åŒè‰²çƒèƒ†æ‹–æŠ•æ³¨é¢„æµ‹ç»“æœ - ä¼˜åŒ–ç‰ˆ\n")
        f.write("=" * 70 + "\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"é‡‡æ ·æ¬¡æ•°: {len(all_samples)}\n")
        f.write(f"é€‰å‡ºç»„æ•°: {len(predictions)}\n\n")

        # é‡‡æ ·ç»Ÿè®¡
        all_expected = [p['total_expected'] for p in all_samples]
        f.write("ä¸€ã€é‡‡æ ·ç»Ÿè®¡\n")
        f.write("-" * 70 + "\n")
        f.write(f"  æœŸæœ›å‘½ä¸­ - æœ€é«˜: {max(all_expected):.3f}\n")
        f.write(f"           å¹³å‡: {np.mean(all_expected):.3f}\n")
        f.write(f"           æœ€ä½: {min(all_expected):.3f}\n")
        f.write(f"           æ ‡å‡†å·®: {np.std(all_expected):.3f}\n\n")

        f.write("äºŒã€èƒ†æ‹–ç­–ç•¥è¯´æ˜\n")
        f.write("-" * 70 + "\n")
        f.write(f"  çº¢çƒï¼šèƒ†{N_DAN_RED}ä¸ª + æ‹–{N_TUO_HOT_RED}ä¸ª(çƒ­åŒº) + æ‹–{N_TUO_COLD_RED}ä¸ª(å†·åŒº)\n")
        f.write(f"  è“çƒï¼šèƒ†{N_DAN_BLUE}ä¸ª + æ‹–{N_TUO_BLUE}ä¸ª\n")
        f.write(f"  åŸç†ï¼šè’™ç‰¹å¡æ´›é‡‡æ ·({len(all_samples)}æ¬¡) + ç²¾è‹±é€‰æ‹©(TOP {len(predictions)})\n\n")

        f.write("ä¸‰ã€é¢„æµ‹å·ç  (TOP SELECTED)\n")
        f.write("-" * 70 + "\n")

        for i, pred in enumerate(predictions, 1):
            f.write(f"\nã€é¢„æµ‹{i}ã€‘ æ ·æœ¬ID: #{pred['sample_id']}\n")
            f.write(f"  ğŸŸ¥ çº¢çƒèƒ†ç : {', '.join([f'{n:02d}' for n in pred['dan_red']])}\n")
            f.write(f"  ğŸŸ¨ çº¢çƒæ‹–ç : {', '.join([f'{n:02d}' for n in pred['tuo_red']])}\n")
            f.write(f"     â””â”€ çƒ­åŒº: {[f'{n:02d}' for n in sorted(pred['tuo_red'][:N_TUO_HOT_RED])]}\n")
            f.write(f"     â””â”€ å†·åŒº: {[f'{n:02d}' for n in sorted(pred['tuo_red'][N_TUO_HOT_RED:])]}\n")
            f.write(f"  ğŸ”µ è“çƒèƒ†ç : {', '.join([f'{n:02d}' for n in pred['dan_blue']])}\n")
            f.write(f"  ğŸŸ¦ è“çƒæ‹–ç : {', '.join([f'{n:02d}' for n in pred['tuo_blue']])}\n")
            f.write(f"  ğŸ“Š çº¢çƒæ± : {len(pred['red_pool'])}ä¸ª | è“çƒæ± : {len(pred['blue_pool'])}ä¸ª\n")
            f.write(f"  ğŸ“ˆ æœŸæœ›å‘½ä¸­: çº¢{pred['red_stats']['expected_hits']:.2f} | "
                    f"è“{pred['blue_stats']['expected_hits']:.2f} | "
                    f"æ€»è®¡{pred['total_expected']:.2f}\n")

        f.write("\n\nå››ã€å·ç æ± æ±‡æ€»ç»Ÿè®¡ (TOP 10)\n")
        f.write("-" * 70 + "\n")

        dan_counts = {i: 0 for i in range(1, 34)}
        tuo_counts = {i: 0 for i in range(1, 34)}

        for pred in predictions:
            for n in pred['dan_red']:
                dan_counts[n] += 1
            for n in pred['tuo_red']:
                tuo_counts[n] += 1

        f.write("\n  çº¢çƒç»Ÿè®¡ï¼ˆå„æ•°å­—åœ¨TOP 10é¢„æµ‹ä¸­å‡ºç°çš„æ¬¡æ•°ï¼‰:\n")
        f.write(f"  {'å·ç ':^6} {'èƒ†ç æ¬¡æ•°':^10} {'æ‹–ç æ¬¡æ•°':^10} {'æ€»æ¬¡æ•°':^10}\n")
        f.write("  " + "-" * 40 + "\n")
        for i in range(1, 34):
            dan_c = dan_counts[i]
            tuo_c = tuo_counts[i]
            total = dan_c + tuo_c
            f.write(f"  {i:^6} {dan_c:^10} {tuo_c:^10} {total:^10}\n")

        # ========== ä¿®å¤éƒ¨åˆ†ï¼šå®Œæ•´æ¦‚ç‡æ’å ==========
        f.write("\n  å®Œæ•´æ¦‚ç‡æ’åï¼ˆçº¢çƒï¼‰:\n")
        sorted_reds = sorted(red_probs.items(), key=lambda x: x[1], reverse=True)
        for i, (num, prob) in enumerate(sorted_reds, 1):
            deviation = (prob - 1 / 33) / (1 / 33) * 100
            sign = '+' if deviation > 0 else ''
            f.write(f"  {i:3d}. {num:02d}: {prob:.5f} ({sign}{deviation:.1f}%)\n")

        f.write("\n  å®Œæ•´æ¦‚ç‡æ’åï¼ˆè“çƒï¼‰:\n")
        sorted_blues = sorted(blue_probs.items(), key=lambda x: x[1], reverse=True)
        for i, (num, prob) in enumerate(sorted_blues, 1):
            deviation = (prob - 1 / 16) / (1 / 16) * 100
            sign = '+' if deviation > 0 else ''
            f.write(f"  {i:3d}. {num:02d}: {prob:.5f} ({sign}{deviation:.1f}%)\n")

        f.write("\n\näº”ã€ä¼˜åŒ–æ•ˆæœåˆ†æ\n")
        f.write("-" * 70 + "\n")
        best_selected = predictions[0]['total_expected']
        worst_selected = predictions[-1]['total_expected']
        improvement = (best_selected - np.mean(all_expected)) / np.mean(all_expected) * 100

        f.write(f"  åŸå§‹å¹³å‡æœŸæœ›å‘½ä¸­: {np.mean(all_expected):.3f}\n")
        f.write(f"  æœ€ä½³é€‰ä¸­æœŸæœ›å‘½ä¸­: {best_selected:.3f}\n")
        f.write(f"  æœ€å·®é€‰ä¸­æœŸæœ›å‘½ä¸­: {worst_selected:.3f}\n")
        f.write(f"  ä¼˜åŒ–æå‡å¹…åº¦: +{improvement:.2f}%\n")
        f.write(f"  è¶…è¶Šæ ·æœ¬æ¯”ä¾‹: {(sum(1 for e in all_expected if e >= worst_selected) / len(all_expected) * 100):.1f}%\n")

    print(f"   âœ… optimized_predictions.txt")

    # ä¿å­˜CSVæ ¼å¼
    csv_data = []
    for pred in predictions:
        row = {
            'é¢„æµ‹ç»„': f"TOP{predictions.index(pred) + 1}",
            'æ ·æœ¬ID': pred['sample_id'],
            'çº¢çƒèƒ†ç ': ','.join([f'{n:02d}' for n in pred['dan_red']]),
            'çº¢çƒæ‹–ç _çƒ­åŒº': ','.join([f'{n:02d}' for n in sorted(pred['tuo_red'][:N_TUO_HOT_RED])]),
            'çº¢çƒæ‹–ç _å†·åŒº': ','.join([f'{n:02d}' for n in sorted(pred['tuo_red'][N_TUO_HOT_RED:])]),
            'çº¢çƒæ‹–ç _å…¨éƒ¨': ','.join([f'{n:02d}' for n in pred['tuo_red']]),
            'è“çƒèƒ†ç ': ','.join([f'{n:02d}' for n in pred['dan_blue']]),
            'è“çƒæ‹–ç ': ','.join([f'{n:02d}' for n in pred['tuo_blue']]),
            'çº¢çƒæ± å¤§å°': len(pred['red_pool']),
            'è“çƒæ± å¤§å°': len(pred['blue_pool']),
            'çº¢çƒæœŸæœ›å‘½ä¸­': round(pred['red_stats']['expected_hits'], 3),
            'è“çƒæœŸæœ›å‘½ä¸­': round(pred['blue_stats']['expected_hits'], 3),
            'æ€»æœŸæœ›å‘½ä¸­': round(pred['total_expected'], 3)
        }
        csv_data.append(row)

    df_csv = pd.DataFrame(csv_data)
    df_csv.to_csv(f'{output_dir}/optimized_predictions.csv', index=False, encoding='utf-8-sig')
    print(f"   âœ… optimized_predictions.csv")

    # ä¿å­˜å…¨éƒ¨é‡‡æ ·æ•°æ®
    sampling_stats = []
    for pred in all_samples:
        sampling_stats.append({
            'æ ·æœ¬ID': pred['sample_id'],
            'çº¢çƒèƒ†ç ': ','.join([f'{n:02d}' for n in pred['dan_red']]),
            'çº¢çƒæ‹–ç ': ','.join([f'{n:02d}' for n in pred['tuo_red']]),
            'è“çƒèƒ†ç ': ','.join([f'{n:02d}' for n in pred['dan_blue']]),
            'è“çƒæ‹–ç ': ','.join([f'{n:02d}' for n in pred['tuo_blue']]),
            'çº¢çƒæœŸæœ›å‘½ä¸­': round(pred['red_stats']['expected_hits'], 3),
            'è“çƒæœŸæœ›å‘½ä¸­': round(pred['blue_stats']['expected_hits'], 3),
            'æ€»æœŸæœ›å‘½ä¸­': round(pred['total_expected'], 3)
        })

    df_sampling = pd.DataFrame(sampling_stats)
    df_sampling = df_sampling.sort_values('æ€»æœŸæœ›å‘½ä¸­', ascending=False)
    df_sampling.to_csv(f'{output_dir}/all_samples.csv', index=False, encoding='utf-8-sig')
    print(f"   âœ… all_samples.csv (å…¨éƒ¨é‡‡æ ·æ•°æ®)")

    return df_csv

def print_summary(predictions, all_samples):
    """æ‰“å°ä¼˜åŒ–æ€»ç»“"""
    print("\n" + "=" * 70)
    print("ğŸ“Š ä¼˜åŒ–æ€»ç»“")
    print("=" * 70)

    all_expected = [p['total_expected'] for p in all_samples]
    top_expected = [p['total_expected'] for p in predictions]

    print(f"\n  ğŸ¯ è’™ç‰¹å¡æ´›é‡‡æ ·: {len(all_samples)} æ¬¡")
    print(f"  ğŸ† ç²¾è‹±é€‰æ‹©: TOP {len(predictions)} ç»„")
    print(f"\n  ğŸ“ˆ æœŸæœ›å‘½ä¸­ç»Ÿè®¡:")
    print(f"     å…¨éƒ¨é‡‡æ ·:")
    print(f"        - æœ€é«˜: {max(all_expected):.3f}")
    print(f"        - å¹³å‡: {np.mean(all_expected):.3f}")
    print(f"        - æœ€ä½: {min(all_expected):.3f}")
    print(f"        - æ ‡å‡†å·®: {np.std(all_expected):.3f}")
    print(f"\n     TOPé€‰ä¸­:")
    print(f"        - æœ€é«˜: {max(top_expected):.3f}")
    print(f"        - å¹³å‡: {np.mean(top_expected):.3f}")
    print(f"        - æœ€ä½: {min(top_expected):.3f}")
    print(f"\n  ğŸ“Š ä¼˜åŒ–æ•ˆæœ:")
    improvement = (predictions[0]['total_expected'] - np.mean(all_expected)) / np.mean(all_expected) * 100
    print(f"     ç›¸æ¯”å¹³å‡æå‡: +{improvement:.2f}%")
    percentile = sum(1 for e in all_expected if e <= predictions[0]['total_expected']) / len(all_expected) * 100
    print(f"     è¶…è¶Šæ ·æœ¬æ¯”ä¾‹: {percentile:.1f}%")

    print(f"\n  ğŸ“ è¾“å‡ºæ–‡ä»¶:")
    print(f"     - optimized_predictions.txt (è¯¦ç»†é¢„æµ‹ç»“æœ)")
    print(f"     - optimized_predictions.csv (é¢„æµ‹ç»“æœè¡¨æ ¼)")
    print(f"     - all_samples.csv (å…¨éƒ¨é‡‡æ ·æ•°æ®)")
    print(f"     - optimized_analysis.png (ç»¼åˆåˆ†æå›¾)")
    print(f"     - optimization_effect.png (ä¼˜åŒ–æ•ˆæœå›¾)")

    print("\n" + "=" * 70)


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("ğŸ¯åŒè‰²çƒèƒ†æ‹–æŠ•æ³¨é¢„æµ‹ - ä¼˜åŒ–ç‰ˆ")
    print("   è’™ç‰¹å¡æ´›é‡‡æ · + ç²¾è‹±é€‰æ‹©")
    print("=" * 70)

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    start_time = datetime.now()

    # 1. åŠ è½½æ•°æ®
    df = load_data()

    # 2. ç”Ÿæˆä¼˜åŒ–é¢„æµ‹
    top_predictions, all_samples, red_probs, blue_probs, x_vals, pdf = \
        generate_optimized_predictions(df, n_samples=N_SAMPLES, top_k=N_TOP_SELECT)

    # 3. ç»˜åˆ¶å›¾è¡¨
    print("\nğŸ“Š æ­£åœ¨ç»˜åˆ¶å¯è§†åŒ–å›¾è¡¨...")
    plot_optimized_charts(top_predictions, all_samples, red_probs, blue_probs, x_vals, pdf, OUTPUT_DIR)

    # 4. ä¿å­˜ç»“æœ
    print("\nğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœ...")
    save_optimized_results(top_predictions, all_samples, red_probs, blue_probs, OUTPUT_DIR)

    # 5. æ‰“å°æ€»ç»“
    print_summary(top_predictions, all_samples)

    # å®Œæˆ
    duration = (datetime.now() - start_time).total_seconds()
    print("\n" + "=" * 70)
    print("âœ… é¢„æµ‹å®Œæˆ!")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print(f"â±ï¸  è€—æ—¶: {duration:.2f} ç§’")
    print("=" * 70)


if __name__ == "__main__":
    main()


# ============== UIå…¼å®¹å±‚ ==============
# ä¸ºlottery_uiæä¾›å…¼å®¹çš„å‡½æ•°æ¥å£

def generate_predictions(df, n=5, n_dan_blue=None, n_tuo_blue=None):
    """
    UIå…¼å®¹çš„é¢„æµ‹å‡½æ•°
    å‚æ•°:
        df: æ•°æ®DataFrame
        n: é¢„æµ‹ç»„æ•°
        n_dan_blue: è“çƒèƒ†ç æ•°ï¼ˆå…¼å®¹å‚æ•°ï¼‰
        n_tuo_blue: è“çƒæ‹–ç æ•°ï¼ˆå…¼å®¹å‚æ•°ï¼‰
    è¿”å›:
        predictions, red_probs, blue_probs, x, pdf
    """
    global N_PREDICTIONS
    
    # æ›´æ–°å‚æ•°
    if n and n > 0:
        N_PREDICTIONS = n
    
    if n_dan_blue:
        N_DAN_BLUE = n_dan_blue
    if n_tuo_blue:
        N_TUO_BLUE = n_tuo_blue
    
    # è°ƒç”¨ä¸»é¢„æµ‹å‡½æ•°
    top_predictions, all_samples, red_probs, blue_probs, x_vals, pdf = \
        generate_optimized_predictions(df, n_samples=N_SAMPLES, top_k=N_PREDICTIONS)
    
    # è½¬æ¢ä¸ºUIæœŸæœ›çš„æ ¼å¼
    result = []
    for pred in top_predictions:
        result.append({
            'red_dan': pred['dan_red'],
            'red_tuo': pred['tuo_red'],
            'blue_dan': pred['dan_blue'],
            'blue_tuo': pred['tuo_blue']
        })
    
    return result, red_probs, blue_probs, x_vals, pdf


def plot_prediction_pools(predictions, red_probs, blue_probs, x, pdf, output_dir):
    """
    UIå…¼å®¹çš„ç»˜å›¾å‡½æ•°
    """
    # è½¬æ¢ä¸ºæ¨¡å—æœŸæœ›çš„æ ¼å¼
    top_preds = []
    for p in predictions:
        top_preds.append({
            'dan_red': p.get('red_dan', p.get('dan_red', [])),
            'tuo_red': p.get('red_tuo', p.get('tuo_red', [])),
            'dan_blue': p.get('blue_dan', p.get('dan_blue', [])),
            'tuo_blue': p.get('blue_tuo', p.get('tuo_blue', [])),
            'red_pool': p.get('red_dan', []) + p.get('red_tuo', []),
            'blue_pool': p.get('blue_dan', []) + p.get('blue_tuo', []),
            'red_stats': {'expected_hits': sum(red_probs.get(n, 0) for n in p.get('red_dan', []) + p.get('red_tuo', []))},
            'blue_stats': {'expected_hits': sum(blue_probs.get(n, 0) for n in p.get('blue_dan', []) + p.get('blue_tuo', []))},
            'sample_id': predictions.index(p),
            'total_expected': sum(red_probs.get(n, 0) for n in p.get('red_dan', []) + p.get('red_tuo', [])) + 
                            sum(blue_probs.get(n, 0) for n in p.get('blue_dan', []) + p.get('blue_tuo', []))
        })
    
    # ç”Ÿæˆå…¨éƒ¨é‡‡æ ·æ•°æ®
    all_samples = top_preds.copy()
    
    # è°ƒç”¨å®é™…ç»˜å›¾å‡½æ•°
    plot_optimized_charts(top_preds, all_samples, red_probs, blue_probs, x, pdf, output_dir)

